use image::{ImageReader, Rgb, RgbImage};
use imageproc::drawing::draw_hollow_rect_mut;
use imageproc::rect::Rect;
use ndarray::CowArray;
use ndarray::{ArrayD, IxDyn};
use ort::execution_providers::CPUExecutionProviderOptions;
use ort::{Environment, ExecutionProvider, SessionBuilder, Value};
use std::sync::Arc;

// ìƒìˆ˜ ì •ì˜
const MODEL_INPUT_SIZE: u32 = 640; // YOLOv9-cëŠ” 640x640 ì…ë ¥ ì‚¬ìš©
const CONFIDENCE_THRESHOLD: f32 = 0.6; // ì‹ ë¢°ë„ ì„ê³„ê°’ì„ ë” ë†’ì„
const NMS_THRESHOLD: f32 = 0.2; // NMS ì„ê³„ê°’ì„ ë” ë‚®ì¶¤
const BBOX_COLOR: Rgb<u8> = Rgb([255, 0, 0]); // ë¹¨ê°„ìƒ‰

// ì„ë² ë””ë“œ ë¦¬ì†ŒìŠ¤: assets/models í´ë”ì˜ ëª¨ë“  onnx íŒŒì¼ì„ ì„ë² ë”© (ë¶„ë¦¬ëœ ëª¨ë“ˆ)
mod models;
use models::get_embedded_model_bytes;
pub use models::get_embedded_model_list;

pub fn get_model_info(selected_file_name: &str) -> (String, u32) {
    // ì§€ì› íŒŒì¼: gelan-c.onnx, gelan-e.onnx, yolov9-c.onnx, yolov9-e.onnx
    let lower = selected_file_name.to_ascii_lowercase();
    let model_name = if lower.contains("gelan-e") {
        "YOLOv9-GELAN-E"
    } else if lower.contains("gelan-c") {
        "YOLOv9-GELAN-C"
    } else if lower.contains("yolov9-e") {
        "YOLOv9-E"
    } else if lower.contains("yolov9-c") {
        "YOLOv9-C"
    } else {
        "YOLOv9-Unknown"
    };
    (model_name.to_string(), MODEL_INPUT_SIZE)
}

/// ê°ì²´ ê²€ì¶œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” êµ¬ì¡°ì²´
#[derive(Debug, Clone, PartialEq)]
pub struct Detection {
    pub bbox: [f32; 4], // [x1, y1, x2, y2] in normalized coordinates (0-1)
    pub confidence: f32,
    pub class_id: u32,
    pub class_name: String,
}

/// ê²€ì¶œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” êµ¬ì¡°ì²´ (ì¶”ë¡  ì‹œê°„ í¬í•¨)
#[derive(Debug, Clone)]
pub struct DetectionResult {
    pub detections: Vec<Detection>,
    pub result_image: RgbImage,
    pub inference_time_ms: f64,
}

/// YOLOv9 COCO í´ë˜ìŠ¤ IDë¥¼ í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
fn yolov9_id_to_label(class_id: u32) -> Option<&'static str> {
    match class_id {
        0 => Some("person"),
        1 => Some("bicycle"),
        2 => Some("car"),
        3 => Some("motorcycle"),
        4 => Some("airplane"),
        5 => Some("bus"),
        6 => Some("train"),
        7 => Some("truck"),
        8 => Some("boat"),
        9 => Some("traffic light"),
        10 => Some("fire hydrant"),
        11 => Some("stop sign"),
        12 => Some("parking meter"),
        13 => Some("bench"),
        14 => Some("bird"),
        15 => Some("cat"),
        16 => Some("dog"),
        17 => Some("horse"),
        18 => Some("sheep"),
        19 => Some("cow"),
        20 => Some("elephant"),
        21 => Some("bear"),
        22 => Some("zebra"),
        23 => Some("giraffe"),
        24 => Some("backpack"),
        25 => Some("umbrella"),
        26 => Some("handbag"),
        27 => Some("tie"),
        28 => Some("suitcase"),
        29 => Some("frisbee"),
        30 => Some("skis"),
        31 => Some("snowboard"),
        32 => Some("sports ball"),
        33 => Some("kite"),
        34 => Some("baseball bat"),
        35 => Some("baseball glove"),
        36 => Some("skateboard"),
        37 => Some("surfboard"),
        38 => Some("tennis racket"),
        39 => Some("bottle"),
        40 => Some("wine glass"),
        41 => Some("cup"),
        42 => Some("fork"),
        43 => Some("knife"),
        44 => Some("spoon"),
        45 => Some("bowl"),
        46 => Some("banana"),
        47 => Some("apple"),
        48 => Some("sandwich"),
        49 => Some("orange"),
        50 => Some("broccoli"),
        51 => Some("carrot"),
        52 => Some("hot dog"),
        53 => Some("pizza"),
        54 => Some("donut"),
        55 => Some("cake"),
        56 => Some("chair"),
        57 => Some("couch"),
        58 => Some("potted plant"),
        59 => Some("bed"),
        60 => Some("dining table"),
        61 => Some("toilet"),
        62 => Some("tv"),
        63 => Some("laptop"),
        64 => Some("mouse"),
        65 => Some("remote"),
        66 => Some("keyboard"),
        67 => Some("cell phone"),
        68 => Some("microwave"),
        69 => Some("oven"),
        70 => Some("toaster"),
        71 => Some("sink"),
        72 => Some("refrigerator"),
        73 => Some("book"),
        74 => Some("clock"),
        75 => Some("vase"),
        76 => Some("scissors"),
        77 => Some("teddy bear"),
        78 => Some("hair drier"),
        79 => Some("toothbrush"),
        _ => None,
    }
}

/// IoU (Intersection over Union) ê³„ì‚°
fn calculate_iou(box1: &[f32; 4], box2: &[f32; 4]) -> f32 {
    let x1 = box1[0].max(box2[0]);
    let y1 = box1[1].max(box2[1]);
    let x2 = box1[2].min(box2[2]);
    let y2 = box1[3].min(box2[3]);

    if x2 <= x1 || y2 <= y1 {
        return 0.0;
    }

    let intersection = (x2 - x1) * (y2 - y1);
    let area1 = (box1[2] - box1[0]) * (box1[3] - box1[1]);
    let area2 = (box2[2] - box2[0]) * (box2[3] - box2[1]);
    let union = area1 + area2 - intersection;

    intersection / union
}

/// Non-Maximum Suppression (NMS) êµ¬í˜„
fn non_maximum_suppression(detections: &mut Vec<Detection>, nms_threshold: f32) {
    if detections.is_empty() {
        return;
    }
    
    // ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì‹ ë¢°ë„ê°€ ë¨¼ì €)
    detections.sort_by(|a, b| b.confidence.partial_cmp(&a.confidence).unwrap());
    
    let mut keep = Vec::new();
    let mut suppressed = vec![false; detections.len()];
    
    for i in 0..detections.len() {
        if suppressed[i] {
            continue;
        }
        
        keep.push(i);
        
        for j in (i + 1)..detections.len() {
            if suppressed[j] {
                continue;
            }
            
            // ê°™ì€ í´ë˜ìŠ¤ì¸ ê²½ìš°ì—ë§Œ NMS ì ìš©
            if detections[i].class_id == detections[j].class_id {
                let iou = calculate_iou(&detections[i].bbox, &detections[j].bbox);
                if iou > nms_threshold {
                    suppressed[j] = true;
                }
            }
        }
    }
    
    // ìœ ì§€í•  ê²€ì¶œ ê²°ê³¼ë§Œ ë‚¨ê¸°ê¸°
    let mut new_detections = Vec::new();
    for &idx in &keep {
        new_detections.push(detections[idx].clone());
    }
    
    *detections = new_detections;
    
    // ìµœëŒ€ ê²€ì¶œ ê°œìˆ˜ ì œí•œ (ì„±ëŠ¥ í–¥ìƒ)
    if detections.len() > 50 {
        detections.truncate(50);
    }
    
    // ì¶”ê°€ í›„ì²˜ë¦¬: ì‘ì€ ë°”ìš´ë”© ë°•ìŠ¤ ì œê±° ë° ì¤‘ë³µ ì œê±°
    post_process_detections(detections);
}

/// ì¶”ê°€ í›„ì²˜ë¦¬: ì‘ì€ ë°•ìŠ¤ ì œê±° ë° ì¤‘ë³µ ì œê±°
fn post_process_detections(detections: &mut Vec<Detection>) {
    if detections.is_empty() {
        return;
    }
    
    // 1. ë„ˆë¬´ ì‘ì€ ë°”ìš´ë”© ë°•ìŠ¤ ì œê±°
    detections.retain(|det| {
        let [x1, y1, x2, y2] = det.bbox;
        let width = x2 - x1;
        let height = y2 - y1;
        let area = width * height;
        
        // ìµœì†Œ ë©´ì  ê¸°ì¤€ (ì „ì²´ ì´ë¯¸ì§€ì˜ 0.5% ì´ìƒ)
        area > 0.005
    });
    
    // 2. ê°™ì€ í´ë˜ìŠ¤ ë‚´ì—ì„œ ë§¤ìš° ìœ ì‚¬í•œ ìœ„ì¹˜ì˜ ë°•ìŠ¤ ì œê±°
    let mut to_remove = Vec::new();
    
    for i in 0..detections.len() {
        for j in (i + 1)..detections.len() {
            if detections[i].class_id == detections[j].class_id {
                let iou = calculate_iou(&detections[i].bbox, &detections[j].bbox);
                
                // IoUê°€ ë†’ê±°ë‚˜ ì¤‘ì‹¬ì ì´ ë§¤ìš° ê°€ê¹Œìš´ ê²½ìš° ì œê±°
                if iou > 0.1 || centers_are_close(&detections[i].bbox, &detections[j].bbox) {
                    // ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²ƒì„ ì œê±°
                    if detections[i].confidence > detections[j].confidence {
                        to_remove.push(j);
                    } else {
                        to_remove.push(i);
                    }
                }
            }
        }
    }
    
    // ì¤‘ë³µ ì œê±° (ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ì œê±°)
    to_remove.sort();
    to_remove.reverse();
    for &idx in &to_remove {
        if idx < detections.len() {
            detections.remove(idx);
        }
    }
}

/// ë‘ ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì ì´ ê°€ê¹Œìš´ì§€ í™•ì¸
fn centers_are_close(box1: &[f32; 4], box2: &[f32; 4]) -> bool {
    let center1_x = (box1[0] + box1[2]) / 2.0;
    let center1_y = (box1[1] + box1[3]) / 2.0;
    let center2_x = (box2[0] + box2[2]) / 2.0;
    let center2_y = (box2[1] + box2[3]) / 2.0;
    
    let distance = ((center1_x - center2_x).powi(2) + (center1_y - center2_y).powi(2)).sqrt();
    
    // ì¤‘ì‹¬ì  ê±°ë¦¬ê°€ 0.1 ì´í•˜ì´ë©´ ê°€ê¹ë‹¤ê³  íŒë‹¨
    distance < 0.1
}

/// ì´ë¯¸ì§€ ì „ì²˜ë¦¬: ë¦¬ì‚¬ì´ì§•, ë ˆí„°ë°•ì‹±, ì •ê·œí™”
pub fn preprocess_image(image: &RgbImage) -> anyhow::Result<ArrayD<f32>> {
    let original_width = image.width() as f32;
    let original_height = image.height() as f32;

    // ì¢…íš¡ë¹„ ê³„ì‚°
    let aspect_ratio = original_width / original_height;

    let (new_width, new_height, offset_x, offset_y) = if aspect_ratio > 1.0 {
        // ê°€ë¡œê°€ ë” ê¸´ ê²½ìš°
        let new_width = MODEL_INPUT_SIZE as f32;
        let new_height = new_width / aspect_ratio;
        let offset_x = 0.0;
        let offset_y = (MODEL_INPUT_SIZE as f32 - new_height) / 2.0;
        (
            new_width as u32,
            new_height as u32,
            offset_x as u32,
            offset_y as u32,
        )
    } else {
        // ì„¸ë¡œê°€ ë” ê¸´ ê²½ìš°
        let new_height = MODEL_INPUT_SIZE as f32;
        let new_width = new_height * aspect_ratio;
        let offset_x = (MODEL_INPUT_SIZE as f32 - new_width) / 2.0;
        let offset_y = 0.0;
        (
            new_width as u32,
            new_height as u32,
            offset_x as u32,
            offset_y as u32,
        )
    };

    // ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (ì¢…íš¡ë¹„ ìœ ì§€)
    let resized = image::imageops::resize(
        image,
        new_width,
        new_height,
        image::imageops::FilterType::Triangle,
    );

    // ì •ì‚¬ê°í˜• ìº”ë²„ìŠ¤ ìƒì„± (íšŒìƒ‰ ë°°ê²½)
    let mut canvas = RgbImage::new(MODEL_INPUT_SIZE, MODEL_INPUT_SIZE);
    let padding_color = Rgb([114, 114, 114]); // íšŒìƒ‰ íŒ¨ë”©

    // ìº”ë²„ìŠ¤ë¥¼ íŒ¨ë”© ìƒ‰ìƒìœ¼ë¡œ ì±„ìš°ê¸°
    for pixel in canvas.pixels_mut() {
        *pixel = padding_color;
    }

    // ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ë¥¼ ìº”ë²„ìŠ¤ ì¤‘ì•™ì— ë°°ì¹˜
    for y in 0..new_height {
        for x in 0..new_width {
            let canvas_x = x + offset_x;
            let canvas_y = y + offset_y;
            if canvas_x < MODEL_INPUT_SIZE && canvas_y < MODEL_INPUT_SIZE {
                canvas.put_pixel(canvas_x, canvas_y, *resized.get_pixel(x, y));
            }
        }
    }

    // HWC -> CHW ë³€í™˜ ë° ì •ê·œí™” (0~1)
    let mut input_data =
        Vec::with_capacity(1 * 3 * MODEL_INPUT_SIZE as usize * MODEL_INPUT_SIZE as usize);
    for c in 0..3 {
        for y in 0..MODEL_INPUT_SIZE {
            for x in 0..MODEL_INPUT_SIZE {
                let pixel_value = canvas.get_pixel(x, y)[c as usize] as f32 / 255.0;
                input_data.push(pixel_value);
            }
        }
    }

    // í…ì„œ ìƒì„±
    Ok(ArrayD::from_shape_vec(
        IxDyn(&[1, 3, MODEL_INPUT_SIZE as usize, MODEL_INPUT_SIZE as usize]),
        input_data,
    )?)
}

/// ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜
fn sigmoid(x: f32) -> f32 {
    1.0 / (1.0 + (-x).exp())
}

/// YOLOv9 ëª¨ë¸ ì¶œë ¥ íŒŒì‹±
pub fn parse_yolov9_outputs(
    output_tensor: &ndarray::ArrayViewD<f32>,
    original_width: u32,
    original_height: u32,
    confidence_threshold: f32,
    nms_threshold: f32,
) -> anyhow::Result<Vec<Detection>> {
    let mut detections = Vec::new();
    
    // ì¶œë ¥ í…ì„œ í˜•íƒœ í™•ì¸
    let shape = output_tensor.shape();
    println!("ğŸ” Output tensor shape: {:?}", shape);
    
    if shape.len() != 3 {
        return Err(anyhow::anyhow!("Invalid output tensor shape: expected 3 dimensions"));
    }
    
    // ë‹¤ì–‘í•œ YOLOv9 ì¶œë ¥ í˜•íƒœ ì§€ì›
    let (num_boxes, num_classes) = if shape[1] == 84 {
        // YOLOv9-C: (1, 84, 8400) í˜•íƒœ
        (shape[2], 80)
    } else if shape[1] == 85 {
        // YOLOv9 with objectness: (1, 85, N) í˜•íƒœ
        (shape[2], 80)
    } else {
        // ê¸°íƒ€ í˜•íƒœ ì‹œë„
        println!("âš ï¸ Unexpected shape: {:?}, trying alternative parsing", shape);
        (shape[2], shape[1] - 4)
    };
    
    println!("ğŸ“Š Parsing {} boxes with {} classes", num_boxes, num_classes);
    
    // ì¶œë ¥ ë°ì´í„°ë¥¼ (84, 8400) í˜•íƒœë¡œ ë³€í™˜
    let output_data = output_tensor.to_owned();
    
    // ë°”ìš´ë”© ë°•ìŠ¤ì™€ í´ë˜ìŠ¤ ì ìˆ˜ ë¶„ë¦¬
    let boxes = output_data.slice(ndarray::s![0, 0..4, ..]); // (4, N): x, y, w, h
    let scores = output_data.slice(ndarray::s![0, 4.., ..]); // (80, N): class scores
    
    // ë””ë²„ê¹…: ì²« ë²ˆì§¸ ë°•ìŠ¤ì˜ ê°’ë“¤ í™•ì¸
    if num_boxes > 0 {
        let first_box = boxes.slice(ndarray::s![.., 0]);
        let first_scores = scores.slice(ndarray::s![.., 0]);
        println!("ğŸ” First box: {:?}", first_box.to_vec());
        println!("ğŸ” First scores (first 10): {:?}", first_scores.slice(ndarray::s![..10]).to_vec());
    }
    
    for box_idx in 0..num_boxes {
        // ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (center_x, center_y, width, height) - í”½ì…€ ì¢Œí‘œë¡œ ì¶œë ¥ë¨
        let cx = boxes[[0, box_idx]];
        let cy = boxes[[1, box_idx]];
        let w = boxes[[2, box_idx]];
        let h = boxes[[3, box_idx]];
        
        // í”½ì…€ ì¢Œí‘œë¥¼ ì •ê·œí™”ëœ ì¢Œí‘œë¡œ ë³€í™˜ (640x640 ê¸°ì¤€)
        let cx_norm = cx / MODEL_INPUT_SIZE as f32;
        let cy_norm = cy / MODEL_INPUT_SIZE as f32;
        let w_norm = w / MODEL_INPUT_SIZE as f32;
        let h_norm = h / MODEL_INPUT_SIZE as f32;
        
        // ë” ì—„ê²©í•œ ë°”ìš´ë”© ë°•ìŠ¤ ê²€ì¦ (ì •ê·œí™”ëœ ì¢Œí‘œ ê¸°ì¤€)
        if w_norm <= 0.0 || h_norm <= 0.0 || w_norm > 1.0 || h_norm > 1.0 {
            continue;
        }
        
        // center ì¢Œí‘œê°€ ì´ë¯¸ì§€ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        if cx_norm < 0.0 || cx_norm > 1.0 || cy_norm < 0.0 || cy_norm > 1.0 {
            continue;
        }
        
        // í´ë˜ìŠ¤ í™•ë¥  ê³„ì‚° (ì‹œê·¸ëª¨ì´ë“œ ì ìš©)
        let mut max_conf = 0.0;
        let mut best_class = 0;
        
        for class_idx in 0..num_classes {
            let raw_score = scores[[class_idx, box_idx]];
            // ì ìˆ˜ ìŠ¤ì¼€ì¼ë§ (ë§¤ìš° ì‘ì€ ê°’ë“¤ì„ í™•ëŒ€)
            let scaled_score = raw_score * 1000.0; // ìŠ¤ì¼€ì¼ë§ íŒ©í„°
            let conf = sigmoid(scaled_score); // ì‹œê·¸ëª¨ì´ë“œ ì ìš©
            
            if conf > max_conf {
                max_conf = conf;
                best_class = class_idx;
            }
        }
        
        // ì‹ ë¢°ë„ ì„ê³„ê°’ í™•ì¸ (GUIì—ì„œ ì„¤ì •í•œ ê°’ ì‚¬ìš©)
        if max_conf > confidence_threshold {
            // ì •ê·œí™”ëœ ì¢Œí‘œë¡œ center_x, center_y, width, height -> x1, y1, x2, y2 ë³€í™˜
            let x1 = (cx_norm - w_norm / 2.0).max(0.0).min(1.0);
            let y1 = (cy_norm - h_norm / 2.0).max(0.0).min(1.0);
            let x2 = (cx_norm + w_norm / 2.0).max(0.0).min(1.0);
            let y2 = (cy_norm + h_norm / 2.0).max(0.0).min(1.0);
            
            // ë” ì—„ê²©í•œ ë°”ìš´ë”© ë°•ìŠ¤ ìœ íš¨ì„± ê²€ì¦
            if x1 >= x2 || y1 >= y2 || 
               (x2 - x1) < 0.02 || (y2 - y1) < 0.02 ||  // ìµœì†Œ í¬ê¸° ì¦ê°€
               (x2 - x1) > 0.95 || (y2 - y1) > 0.95 {   // ìµœëŒ€ í¬ê¸° ì œí•œ (ì „ì²´ ì´ë¯¸ì§€ ì œì™¸)
                continue;
            }
            
            // ë ˆí„°ë°•ì‹± ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
            let original_bbox = letterbox_to_original_coords([x1, y1, x2, y2], original_width, original_height);
            
            // ë³€í™˜ëœ ì¢Œí‘œ ìœ íš¨ì„± ê²€ì¦
            let [ox1, oy1, ox2, oy2] = original_bbox;
            if ox1 >= ox2 || oy1 >= oy2 || 
               (ox2 - ox1) < 0.02 || (oy2 - oy1) < 0.02 ||
               (ox2 - ox1) > 0.95 || (oy2 - oy1) > 0.95 {
                continue;
            }
            
            if let Some(class_name) = yolov9_id_to_label(best_class as u32) {
                // ë””ë²„ê¹…: ë†’ì€ ì‹ ë¢°ë„ ê²€ì¶œë§Œ ì¶œë ¥
                if max_conf > 0.7 {
                    println!("ğŸ¯ High confidence detection: {} ({}%) at [{:.3}, {:.3}, {:.3}, {:.3}]", 
                             class_name, (max_conf * 100.0) as i32, ox1, oy1, ox2, oy2);
                }
                
                detections.push(Detection {
                    bbox: original_bbox,
                    confidence: max_conf,
                    class_id: best_class as u32,
                    class_name: class_name.to_string(),
                });
            }
        }
    }
    
    // NMS ì ìš© (GUIì—ì„œ ì„¤ì •í•œ ì„ê³„ê°’ ì‚¬ìš©)
    non_maximum_suppression(&mut detections, nms_threshold);
    
    Ok(detections)
}

/// ë ˆí„°ë°•ì‹± ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
fn letterbox_to_original_coords(
    bbox: [f32; 4], // [x1, y1, x2, y2] in letterboxed coordinates (0-1)
    original_width: u32,
    original_height: u32,
) -> [f32; 4] {
    let aspect_ratio = original_width as f32 / original_height as f32;

    let (scale, offset_x, offset_y) = if aspect_ratio > 1.0 {
        // ê°€ë¡œê°€ ë” ê¸´ ê²½ìš°
        let scale = MODEL_INPUT_SIZE as f32 / original_width as f32;
        let offset_x = 0.0;
        let offset_y = (MODEL_INPUT_SIZE as f32 - MODEL_INPUT_SIZE as f32 / aspect_ratio) / 2.0;
        (scale, offset_x, offset_y)
    } else {
        // ì„¸ë¡œê°€ ë” ê¸´ ê²½ìš°
        let scale = MODEL_INPUT_SIZE as f32 / original_height as f32;
        let offset_x = (MODEL_INPUT_SIZE as f32 - MODEL_INPUT_SIZE as f32 * aspect_ratio) / 2.0;
        let offset_y = 0.0;
        (scale, offset_x, offset_y)
    };

    // ë ˆí„°ë°•ì‹± ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
    let x1_pixel = bbox[0] * MODEL_INPUT_SIZE as f32;
    let y1_pixel = bbox[1] * MODEL_INPUT_SIZE as f32;
    let x2_pixel = bbox[2] * MODEL_INPUT_SIZE as f32;
    let y2_pixel = bbox[3] * MODEL_INPUT_SIZE as f32;

    // íŒ¨ë”© ì œê±°
    let x1_unpadded = (x1_pixel - offset_x) / scale;
    let y1_unpadded = (y1_pixel - offset_y) / scale;
    let x2_unpadded = (x2_pixel - offset_x) / scale;
    let y2_unpadded = (y2_pixel - offset_y) / scale;

    // ì›ë³¸ ì´ë¯¸ì§€ ë²”ìœ„ë¡œ í´ë¦¬í•‘
    let x1_final = x1_unpadded.max(0.0).min(original_width as f32);
    let y1_final = y1_unpadded.max(0.0).min(original_height as f32);
    let x2_final = x2_unpadded.max(0.0).min(original_width as f32);
    let y2_final = y2_unpadded.max(0.0).min(original_height as f32);

    // ì •ê·œí™”ëœ ì¢Œí‘œë¡œ ë³€í™˜ (0-1)
    [
        x1_final / original_width as f32,
        y1_final / original_height as f32,
        x2_final / original_width as f32,
        y2_final / original_height as f32,
    ]
}

/// ê²€ì¶œëœ ê°ì²´ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
pub fn draw_detections(image: &mut RgbImage, detections: &[Detection]) {
    for detection in detections {
        let [x1, y1, x2, y2] = detection.bbox;
        
        // ì¢Œí‘œ ìœ íš¨ì„± ê²€ì¦
        if x1 >= x2 || y1 >= y2 || x1 < 0.0 || y1 < 0.0 || x2 > 1.0 || y2 > 1.0 {
            continue;
        }
        
        let x1 = (x1 * image.width() as f32) as i32;
        let y1 = (y1 * image.height() as f32) as i32;
        let x2 = (x2 * image.width() as f32) as i32;
        let y2 = (y2 * image.height() as f32) as i32;

        // í”½ì…€ ì¢Œí‘œ ìœ íš¨ì„± í™•ì¸
        if x1 >= x2 || y1 >= y2 || x1 < 0 || y1 < 0 || x2 > image.width() as i32 || y2 > image.height() as i32 {
            continue;
        }

        let rect = Rect::at(x1, y1).of_size((x2 - x1).max(1) as u32, (y2 - y1).max(1) as u32);
        draw_hollow_rect_mut(image, rect, BBOX_COLOR);
    }
}

/// ëª¨ë¸ ì„¸ì…˜ì„ ìºì‹œí•˜ëŠ” êµ¬ì¡°ì²´
pub struct ModelCache {
    environment: Arc<Environment>,
    session: Option<ort::InMemorySession<'static>>,
    current_model_file: Option<String>,
}

impl ModelCache {
    /// ìƒˆë¡œìš´ ëª¨ë¸ ìºì‹œ ìƒì„±
    pub fn new() -> anyhow::Result<Self> {
        let environment = Arc::new(
            Environment::builder()
                .with_name("yolov9-embedded")
                .with_log_level(ort::LoggingLevel::Warning)
                .build()?,
        );

        Ok(Self {
            environment,
            session: None,
            current_model_file: None,
        })
    }

    pub fn get_session(&mut self, model_file_name: &str) -> anyhow::Result<&ort::InMemorySession<'static>> {
        let need_reload = match &self.current_model_file {
            Some(cur) => cur != model_file_name,
            None => true,
        };
        if need_reload {
            #[cfg(target_os = "macos")]
            let session = SessionBuilder::new(&self.environment)?
                .with_execution_providers([
                    ExecutionProvider::CoreML(CoreMLExecutionProviderOptions {
                        use_cpu_only: false,
                        enable_on_subgraph: true,
                        only_enable_device_with_ane: true, // M4 ANE í™œìš©
                    }),
                    ExecutionProvider::CPU(CPUExecutionProviderOptions::default()),
                ])?
                // 1. ìµœì í™” ë ˆë²¨ ì¡°ì • (ì„±ëŠ¥ vs ì´ˆê¸°í™” ì‹œê°„)
                .with_optimization_level(ort::GraphOptimizationLevel::Level1)?
                // 2. ìŠ¤ë ˆë“œ ì„¤ì • ìµœì í™” (M4 Mac ê¸°ì¤€)
                .with_intra_threads(4)? // M4 ì„±ëŠ¥ ì½”ì–´ ê°œìˆ˜
                .with_inter_threads(2)? // ë³‘ë ¬ ì‹¤í–‰ìš©
                .with_parallel_execution(false)? // YOLOv9ëŠ” ìˆœì°¨ ì‹¤í–‰ì´ ë” ë¹ ë¦„
                // 3. ë©”ëª¨ë¦¬ ìµœì í™”
                .with_memory_pattern(true)? // ê³ ì • ì…ë ¥ í¬ê¸°ë¼ë©´ í™œì„±í™”
                .with_allocator(ort::AllocatorType::Device)? // GPU ë©”ëª¨ë¦¬ ì‚¬ìš©
                .with_model_from_memory(self.load_embedded_model_bytes(model_file_name)?)?;
            #[cfg(not(target_os = "macos"))]
            let session = SessionBuilder::new(&self.environment)?
                .with_execution_providers([ExecutionProvider::CPU(
                    CPUExecutionProviderOptions::default(),
                )])?
                // 1. ìµœì í™” ë ˆë²¨ ì¡°ì • (ì„±ëŠ¥ vs ì´ˆê¸°í™” ì‹œê°„)
                .with_optimization_level(ort::GraphOptimizationLevel::Level1)?
                // 2. ìŠ¤ë ˆë“œ ì„¤ì • ìµœì í™”
                .with_intra_threads(16)? // ì„±ëŠ¥ ì½”ì–´ ê°œìˆ˜
                .with_inter_threads(8)? // ë³‘ë ¬ ì‹¤í–‰ìš©
                .with_parallel_execution(false)? // YOLOv9ëŠ” ìˆœì°¨ ì‹¤í–‰ì´ ë” ë¹ ë¦„
                // 3. ë©”ëª¨ë¦¬ ìµœì í™”
                .with_memory_pattern(true)? // ê³ ì • ì…ë ¥ í¬ê¸°ë¼ë©´ í™œì„±í™”
                .with_allocator(ort::AllocatorType::Device)? // GPU ë©”ëª¨ë¦¬ ì‚¬ìš©
                .with_model_from_memory(self.load_embedded_model_bytes(model_file_name)?)?;

            self.session = Some(session);
            self.current_model_file = Some(model_file_name.to_string());
            println!("Loading model: {} - Optimized for inference", model_file_name);
        }

        match self.session.as_ref() {
            Some(session) => Ok(session),
            None => Err(anyhow::anyhow!("Model session is not initialized")),
        }
    }

    /// ì„ë² ë””ë“œ ëª¨ë¸ ë°”ì´íŠ¸ ë¡œë“œ
    fn load_embedded_model_bytes(&self, file_name: &str) -> anyhow::Result<&'static [u8]> {
        get_embedded_model_bytes(file_name)
    }
}

/// ë©”ì¸ ê°ì²´ ê²€ì¶œ í•¨ìˆ˜ (ìºì‹œ ì‚¬ìš©)
pub fn detect_objects_with_cache(
    image_data: &[u8],
    cache: &mut ModelCache,
    model_file_name: &str,
) -> anyhow::Result<DetectionResult> {
    // ì´ë¯¸ì§€ ë¡œë“œ
    let img = ImageReader::new(std::io::Cursor::new(image_data))
        .with_guessed_format()?
        .decode()?
        .to_rgb8();

    // ìºì‹œëœ ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° (ì„ íƒëœ ëª¨ë¸ ê¸°ì¤€)
    let session = cache.get_session(model_file_name)?;

    // ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    let input_array = preprocess_image(&img)?;
    let cow_array = CowArray::from(&input_array);
    let input_value = Value::from_array(session.allocator(), &cow_array)?;

    // ì¶”ë¡  ì‹œê°„ ì¸¡ì • ì‹œì‘
    let start_time = std::time::Instant::now();

    // ì¶”ë¡  ì‹¤í–‰
    let outputs = session.run(vec![input_value])?;

    // ì¶”ë¡  ì‹œê°„ ì¸¡ì • ì¢…ë£Œ
    let inference_time = start_time.elapsed();
    let inference_time_ms = inference_time.as_secs_f64() * 1000.0;

    // ê²°ê³¼ íŒŒì‹±
    let mut detections = Vec::new();
    if let Some(output) = outputs.first() {
        let output_tensor = output.try_extract::<f32>()?;
        let output_view = output_tensor.view();

        // YOLOv9 ì¶œë ¥ íŒŒì‹± (ê¸°ë³¸ ì„ê³„ê°’ ì‚¬ìš©)
        detections = parse_yolov9_outputs(&output_view, img.width(), img.height(), CONFIDENCE_THRESHOLD, NMS_THRESHOLD)?;
    }

    // ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜ (bboxëŠ” GUIì—ì„œ ì˜¤ë²„ë ˆì´ë¡œ ë Œë”ë§)
    let result_image = img.clone();

    Ok(DetectionResult {
        detections,
        result_image,
        inference_time_ms,
    })
}

/// ë©”ì¸ ê°ì²´ ê²€ì¶œ í•¨ìˆ˜ (ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©)
pub fn detect_objects(image_data: &[u8]) -> anyhow::Result<DetectionResult> {
    // ModelCacheë¥¼ ìƒì„±í•˜ì—¬ ì‚¬ìš©
    let mut cache = ModelCache::new()?;
    detect_objects_with_cache(image_data, &mut cache, "gelan-e.onnx")
}

/// ì„¤ì • ê°€ëŠ¥í•œ ì„ê³„ê°’ìœ¼ë¡œ ê°ì²´ ê²€ì¶œ í•¨ìˆ˜
pub fn detect_objects_with_settings(
    image_data: &[u8],
    cache: &mut ModelCache,
    model_file_name: &str,
    confidence_threshold: f32,
    nms_threshold: f32,
) -> anyhow::Result<DetectionResult> {
    // ì´ë¯¸ì§€ ë¡œë“œ
    let img = ImageReader::new(std::io::Cursor::new(image_data))
        .with_guessed_format()?
        .decode()?
        .to_rgb8();

    // ìºì‹œëœ ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° (ì„ íƒëœ ëª¨ë¸ ê¸°ì¤€)
    let session = cache.get_session(model_file_name)?;

    // ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    let input_array = preprocess_image(&img)?;
    let cow_array = CowArray::from(&input_array);
    let input_value = Value::from_array(session.allocator(), &cow_array)?;

    // ì¶”ë¡  ì‹œê°„ ì¸¡ì • ì‹œì‘
    let start_time = std::time::Instant::now();

    // ì¶”ë¡  ì‹¤í–‰
    let outputs = session.run(vec![input_value])?;

    // ì¶”ë¡  ì‹œê°„ ì¸¡ì • ì¢…ë£Œ
    let inference_time = start_time.elapsed();
    let inference_time_ms = inference_time.as_secs_f64() * 1000.0;

    // ê²°ê³¼ íŒŒì‹±
    let mut detections = Vec::new();
    if let Some(output) = outputs.first() {
        let output_tensor = output.try_extract::<f32>()?;
        let output_view = output_tensor.view();

        // YOLOv9 ì¶œë ¥ íŒŒì‹± (ì„¤ì •ëœ ì„ê³„ê°’ ì‚¬ìš©)
        detections = parse_yolov9_outputs(&output_view, img.width(), img.height(), confidence_threshold, nms_threshold)?;
    }

    // ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜ (bboxëŠ” GUIì—ì„œ ì˜¤ë²„ë ˆì´ë¡œ ë Œë”ë§)
    let result_image = img.clone();

    Ok(DetectionResult {
        detections,
        result_image,
        inference_time_ms,
    })
}


